# Case Study - Julien CHARLET

Bonjour Ariane, bonjour Mariyem ! üëã

D'abord, merci pour le temps pass√© √† l'√©tude de ce case study.

Commen√ßons !

<br />

## üìã M√©thodologie globale
1. Appr√©hension des guidelines du Notion
2. Appr√©hension des fichiers .csv (compr√©hension des champs, du lien entre les fichiers)
3. Ingestion des deux fichiers dans Snowflake via la UI
4. Travail des requ√™tes de mod√©lisation dans la UI pour visualisation des r√©sultats en direct
5. Cr√©ation d'un projet GitHub, de l'arborescence et des fichiers du projet dbt puis int√©gration des requ√™tes
6. Cr√©ation du template du dashboard sur Miro
7. Cr√©ation du dashboard sur Tableau

<br />

## üîé M√©thodologie d√©taill√©e

### Mod√©lisation de la donn√©e
#### ‚ñ∂ Les tables de staging
> *stg_intercom__conversations*<br />
> *stg_intercom__conversation_parts*

- Renommage des champs pour expliciter l'origine (conversation ou conversation_part) et ainsi √©viter les confusions dans les futures jointures
- Nettoyage du champ assigned_to de conversation_parts pour transformation en JSON (remplacement de None en null et des apostrophes en guillemets)
- Extraction de champs dans les colonnes de type JSON (en direct ou en aplatissant des champs √† plusieurs niveaux)
- Cr√©ation de champs de date "_on" en addition des champs "_at" en pr√©vision de futures analyses
- Cr√©ation de flags (ie. *is_csat_rated*) en pr√©vision du calcul de KPIs
- Organisation des champs pour une meilleure appr√©hension de la table (via la cat√©gorisation en commentaires)

#### ‚ñ∂ Les tables interm√©diaires
> *int_intercom__messages*

- Agr√©gation de la staging *stg_intercom__conversation_parts* au niveau conversation_id afin de calculer des KPIs li√©s aux conversations, utilisables dans l'analyse
- Filtrage de la donn√©e pour ne garder que les "Messages" et exclure les "bots"
- Identification d'√©v√®nements (date du premier message, date de la premi√®re r√©ponse)
- Cr√©ation de calculs (nombre de messages, time to answer)
- Cr√©ation de flags/info (jour et p√©riode de journ√©e de la cr√©ation du premier message, SLA) en pr√©vision des analyses

> *int_intercom__agg_conversations*
- Agr√©gation de la staging *stg_intercom__conversations* au niveau conversation_id en supprimant les infos de tags mais en agr√©geant le nom des tags √† des fins d'analyse
- Cette agr√©gation permet de conserver le champ conversation_id comme cl√© primaire dans la table core

> *int_intercom__conversations_tags*
- Agr√©gation de la staging *stg_intercom__conversations* au niveau conversation_id en ne conservant uniquement les infos de tags
- Cette table pourra √™tre appel√©e par exemple dans un Explore dans Looker ou via une Relation dans Tableau pour permettre une analyse plus fine des tags, sans d√©dupliquer les lignes en utilisant la donn√©e li√© aux conversations

#### ‚ñ∂ La table de dimension
> *dim_team*

- Cr√©ation d'une table de mapping facilement actionnable dans le but de relier les assignees √† leur team

#### ‚ñ∂ La table core
> *fct_intercom__support_conversations*

- Permet l'analyse au niveau conversation de l'√©quipe Support rendant faciles les futures agr√©gations dans un dashboard
- Jointure des tables *int_intercom__agg_conversations*, *int_intercom__messages* et *dim_team*
- Filtrage de la donn√©e pour ne garder que les conversations assign√©es √† l'√©quipe Support

#### ‚ñ∂ Configuration

- Tests sur les cl√©s primaires (conversation_id et conversation_part_id) pour v√©rifier le remplissage et l'unicit√© des champs

<br />


### Cr√©ation du template du dashboard

Le mod√®le pr√©sent√© √† Lorette est le suivant : 
</br>

<img width="1081" alt="image" src="https://github.com/user-attachments/assets/39393dbc-e676-43ec-af83-6b1ec12b9993" />

<br />
- L'id√©e derri√®re ce mod√®le de dashboard est de fournir √† Lorette un outil non seulement de reporting (extraction de chiffres de mani√®re simple) mais √©galement un outil d'analyse qui lui permette de donner de la profondeur √† son analyse hebdomadaire.

<br />
- Avec un filtre sur la date de cr√©ation des conversations par d√©faut sur la semaine pr√©c√©dente, Lorette a acc√®s directement √† la performance qui l'int√©resse
- On organise le dashboard avec une partie KPIs et une partie Busyness (cette seconde partie ne pouvant s'analyser comme la premi√®re)
- Les KPIs seront construits sous forme de triptyques : valeur, breakdown, √©volution temporelle (+ breakdown)
1. Le param√®tre BREAKDOWN permet √† Lorette de comparer la performance d'un m√™me KPI d'une dimension choisie
2. Le param√®tre GRANULARITY permet √† Lorette de choisir la granularit√© de dates : par d√©faut en jour pour son analyse hebdo, mais possible de regarder par semaine, mois, quarter..
  


### Cr√©ation du dashboard
